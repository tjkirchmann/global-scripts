#!/bin/bash

# Jupyter Environment Setup Script with UV
# Usage: new-jupyter <project-name>

set -e  # Exit on any error

if [ -z "$1" ]; then
    echo "‚ùå Error: Please provide a project name"
    echo "Usage: new-jupyter <project-name>"
    exit 1
fi

PROJECT_NAME="$1"

# Check if uv is installed
if ! command -v uv &> /dev/null; then
    echo "‚ùå Error: uv is not installed. Please install it first:"
    echo "curl -LsSf https://astral.sh/uv/install.sh | sh"
    exit 1
fi

# Create project directory
if [ -d "$PROJECT_NAME" ]; then
    echo "‚ùå Error: Directory '$PROJECT_NAME' already exists"
    exit 1
fi

mkdir "$PROJECT_NAME"
cd "$PROJECT_NAME"

echo "üìÅ Created directory: $PROJECT_NAME"

# Initialize git repository
git init
echo "üîß Initialized git repository"

# Create Python project with uv
uv init --python 3.11
echo "üêç Initialized Python project with uv"

# Delete main.py
rm hello.py

# Install data science packages
echo "üì¶ Installing data science packages..."
uv add jupyter \
    pandas \
    numpy \
    matplotlib \
    seaborn \
    scikit-learn \
    plotly \
    requests \
    openpyxl \
    xlsxwriter \
    scipy \
    statsmodels \
    ipywidgets \
    tqdm

echo "‚úÖ Installed core data analysis packages"

# Create data directory
mkdir -p data/{raw,processed}
echo "üìä Created data directory structure"

# Copy custom toolbox
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [ -d "$SCRIPT_DIR/tys-toolbox" ]; then
    cp -r "$SCRIPT_DIR/tys-toolbox" ./
    echo "üß∞ Copied custom toolbox"
else
    echo "‚ö†Ô∏è  Warning: tys-toolbox not found in $SCRIPT_DIR"
fi

# Create .gitignore
cat > .gitignore << 'EOF'
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# Jupyter Notebook
.ipynb_checkpoints

# Environment variables
.env

# Data files (uncomment if you want to ignore data)
# data/

# Virtual environment
.venv/
venv/

# IDE
.vscode/
.idea/
*.swp
*.swo

# macOS
.DS_Store

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# PyInstaller
*.manifest
*.spec

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/
EOF

echo "üö´ Created .gitignore file"

# Create main.ipynb with boilerplate
cat > main.ipynb << 'EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Analysis\n",
    "\n",
    "## Overview\n",
    "Brief description of the project and objectives.\n",
    "\n",
    "## Data Sources\n",
    "- Source 1: Description\n",
    "- Source 2: Description\n",
    "\n",
    "## Key Findings\n",
    "- Finding 1\n",
    "- Finding 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Custom toolbox imports\n",
    "from tys_toolbox import *\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"üìä Environment setup complete!\")\n",
    "print(f\"üêç Python version: {sys.version.split()[0]}\")\n",
    "print(f\"üêº Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path('./data')\n",
    "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "# Load your data here\n",
    "# df = pd.read_csv(RAW_DATA_DIR / 'your_file.csv')\n",
    "\n",
    "print(f\"üìÅ Data directories available:\")\n",
    "print(f\"   Raw: {RAW_DATA_DIR}\")\n",
    "print(f\"   Processed: {PROCESSED_DATA_DIR}\")\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
EOF

echo "üìì Created main.ipynb with boilerplate"
# Create README.md
cat > README.md << EOF
# $PROJECT_NAME

## Setup

This project uses [uv](https://github.com/astral-sh/uv) for fast Python package management.

### Installation

1. Install dependencies:
   \`\`\`bash
   uv sync
   \`\`\`

2. Start Jupyter:
   \`\`\`bash
   uv run jupyter lab
   \`\`\`

## Project Structure

\`\`\`
$PROJECT_NAME/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/          # Original, immutable data
‚îÇ   ‚îú‚îÄ‚îÄ processed/    # Cleaned and transformed data
‚îú‚îÄ‚îÄ main.ipynb        # Main analysis notebook
‚îú‚îÄ‚îÄ pyproject.toml    # Project dependencies
‚îî‚îÄ‚îÄ README.md         # This file
\`\`\`

## Data Directory Usage

- **raw/**: Store original data files here
- **processed/**: Save cleaned and processed datasets

## Getting Started

1. Add your raw data to \`data/raw/\`
2. Open \`main.ipynb\`
3. Start analyzing!
EOF

echo "üìñ Created README.md"

# Initial git commit
git add .
git commit -m "Initial commit: Setup Jupyter environment with uv"
echo "üìù Made initial git commit"

# Success message
echo ""
echo "üéâ SUCCESS! Jupyter environment '$PROJECT_NAME' is ready!"
echo ""
echo "üöÄ Next steps:"
echo "   cd $PROJECT_NAME"
echo "   uv run jupyter lab"
echo ""
echo "üìÅ Project structure created:"
echo "   ‚îú‚îÄ‚îÄ main.ipynb (ready to use!)"
echo "   ‚îú‚îÄ‚îÄ data/ (with raw, processed, external subdirs)"
echo "   ‚îú‚îÄ‚îÄ README.md"
echo "   ‚îú‚îÄ‚îÄ .gitignore"
echo "   ‚îî‚îÄ‚îÄ pyproject.toml (with data science packages)"
echo ""